{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('doheon': conda)"
  },
  "interpreter": {
   "hash": "849767edceeeddf53965c2c22dc0d6f4cc62af5f2af22e684245cca2d0b8102d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from gensim.models import Doc2Vec\r\n",
    "from gensim.models.doc2vec import TaggedDocument\r\n",
    "import sentencepiece as spm\r\n",
    "\r\n",
    "from tqdm import trange\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset_train = []\r\n",
    "dataset_test = []\r\n",
    "dataset_all = []\r\n",
    "\r\n",
    "root = \"newsData/\"\r\n",
    "list = os.listdir(root)\r\n",
    "for cat in list:\r\n",
    "    files = os.listdir(root + cat)\r\n",
    "    for i,f in enumerate(files):\r\n",
    "        fname = root + cat + \"/\" + f\r\n",
    "        file = open(fname, \"r\", encoding=\"utf8\")\r\n",
    "        strings = file.read()\r\n",
    "        if i<170:\r\n",
    "            dataset_train.append([strings, cat])\r\n",
    "        else:\r\n",
    "            dataset_test.append([strings,cat])\r\n",
    "        dataset_all.append(strings)\r\n",
    "        file.close()\r\n",
    "\r\n",
    "print(len(dataset_train), len(dataset_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1360 240\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "f = open(\"allsentence.txt\",\"w\", encoding=\"utf8\")\r\n",
    "f.write(\"\".join(dataset_all).replace(\"\\xa0\", \"\"))\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#subword 단위\r\n",
    "corpus = \"allsentence.txt\"\r\n",
    "prefix = \"news\"\r\n",
    "vocab_size = 8000\r\n",
    "spm.SentencePieceTrainer.train(\r\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \r\n",
    "    \" --model_type=bpe\" +\r\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\r\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\r\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\r\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\r\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\r\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "vocab_file = \"news.model\"\r\n",
    "vocab = spm.SentencePieceProcessor()\r\n",
    "vocab.load(vocab_file)\r\n",
    "cab_file = \"news.model\"\r\n",
    "vocab = spm.SentencePieceProcessor()\r\n",
    "vocab.load(vocab_file)\r\n",
    "line = \"안녕하세요 만나서 반갑습니다\"\r\n",
    "pieces = vocab.encode_as_pieces(line)\r\n",
    "ids = vocab.encode_as_ids(line)\r\n",
    "print(line)\r\n",
    "print(pieces)\r\n",
    "print(ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "안녕하세요 만나서 반갑습니다\n",
      "['▁안', '녕', '하', '세요', '▁만나', '서', '▁반', '갑', '습니다']\n",
      "[89, 7577, 6518, 2892, 957, 6521, 126, 7021, 107]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tokened_sp = []\r\n",
    "with trange(len(dataset_all)) as tr:\r\n",
    "    for i in tr:\r\n",
    "        tokened_sp.append(vocab.encode_as_pieces(dataset_all[i]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1600/1600 [00:00<00:00, 2235.07it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class Doc2VecCorpus:\r\n",
    "    def __iter__(self):\r\n",
    "        for idx, doc in enumerate(tokened_sp):\r\n",
    "            yield TaggedDocument(\r\n",
    "                words = doc, \r\n",
    "                tags = [idx])\r\n",
    "\r\n",
    "doc2vec_corpus = Doc2VecCorpus()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "embed_num = 128\r\n",
    "doc2vec_model = Doc2Vec(documents = doc2vec_corpus,dm=2,  vector_size=embed_num, window = 10, min_count = 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "doc2vec_model.docvecs[0]\r\n",
    "\r\n",
    "test_sen = tokened_sp[5]\r\n",
    "doc2vec_model.docvecs.most_similar([doc2vec_model.infer_vector(test_sen)])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-14-35f496b1114a>:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  doc2vec_model.docvecs[0]\n",
      "<ipython-input-14-35f496b1114a>:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  doc2vec_model.docvecs.most_similar([doc2vec_model.infer_vector(test_sen)])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5, 0.9153035879135132),\n",
       " (560, 0.6753875017166138),\n",
       " (574, 0.6555848717689514),\n",
       " (986, 0.5947901606559753),\n",
       " (989, 0.5832820534706116),\n",
       " (929, 0.5810511112213135),\n",
       " (159, 0.5718024969100952),\n",
       " (169, 0.5712486505508423),\n",
       " (147, 0.5702451467514038),\n",
       " (9, 0.5601426362991333)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import numpy as np\r\n",
    "device = torch.device(\"cuda\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class SentenceDataset(Dataset):\r\n",
    "    def __init__(self, dataset, tokenizer, doc2vecmodel, max_len):\r\n",
    "        self.sentences = []\r\n",
    "        with trange(len(dataset)) as tr:\r\n",
    "            for i in tr:\r\n",
    "                sen = dataset[i][0]\r\n",
    "                sen = tokenizer(sen)\r\n",
    "                l = min(max_len, len(sen))\r\n",
    "                sen = sen[:l]\r\n",
    "                sen = doc2vecmodel.infer_vector(sen)\r\n",
    "                self.sentences.append(sen)\r\n",
    "        self.labels = [np.int32(i[1]) for i in dataset]\r\n",
    "\r\n",
    "    def __getitem__(self, i):\r\n",
    "        return (self.sentences[i],self.labels[i])\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return (len(self.labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "max_len = 512\r\n",
    "data_train = SentenceDataset(dataset_train, vocab.encode_as_pieces,doc2vec_model, max_len)\r\n",
    "data_test = SentenceDataset(dataset_test, vocab.encode_as_pieces,doc2vec_model, max_len)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1360/1360 [00:05<00:00, 234.39it/s]\n",
      "100%|██████████| 240/240 [00:01<00:00, 236.88it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "batch_size = 64\r\n",
    "train_dataloader = DataLoader(data_train, batch_size=batch_size, num_workers=5, shuffle=True)\r\n",
    "test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=5, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def calc_accuracy(X,Y):\r\n",
    "    max_vals, max_indices = torch.max(X, 1)\r\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\r\n",
    "    return train_acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "class Classifier(nn.Module):\r\n",
    "    def __init__(self, input_size, num_classes):\r\n",
    "        super(Classifier, self).__init__()\r\n",
    "        self.input_size = input_size\r\n",
    "        self.num_classes = num_classes\r\n",
    "\r\n",
    "        self.linear = nn.Linear(input_size, 64)\r\n",
    "        self.linear2 = nn.Linear(64, num_classes)\r\n",
    "        # self.linear3 = nn.Linear(32, num_classes)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\r\n",
    "    \r\n",
    "        self.fc = nn.Sequential(self.linear, self.dropout, self.relu, self.linear2, self.dropout)\r\n",
    "        # self.fc = nn.Sequential(self.linear, self.dropout, self.relu, self.linear2, self.dropout, self.relu, self.linear3, self.dropout)\r\n",
    "\r\n",
    "    def forward(self, x_input):\r\n",
    "        output = self.fc(x_input)\r\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model = Classifier(embed_num, 8).to(device)\r\n",
    "\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "epochs = 100\r\n",
    "\r\n",
    "with trange(epochs) as tr:\r\n",
    "    for i in tr:\r\n",
    "        itloss = 0\r\n",
    "        trainacc = 0\r\n",
    "        testacc = 0\r\n",
    "        \r\n",
    "        model.train()\r\n",
    "        for batch_id, (input, label) in enumerate(train_dataloader):\r\n",
    "            optimizer.zero_grad()\r\n",
    "            input = input.to(device)\r\n",
    "            label = label.long().to(device)\r\n",
    "            out = model(input)\r\n",
    "            loss = criterion(out, label)\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            itloss += loss.cpu().item()\r\n",
    "            trainacc += calc_accuracy(out,label)\r\n",
    "\r\n",
    "\r\n",
    "        model.eval()\r\n",
    "        for batch_idt, (input, label) in enumerate(test_dataloader):\r\n",
    "            input = input.to(device)\r\n",
    "            label = label.long().to(device)\r\n",
    "            out = model(input)\r\n",
    "            testacc += calc_accuracy(out,label)\r\n",
    "\r\n",
    "        tr.set_postfix(trainacc=\"{0:.3f}\".format(trainacc/(batch_id+1)), loss=\"{0:.3f}\".format(itloss/(batch_id+1)),  testacc=\"{0:.3f}\".format(testacc/(batch_idt+1)))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f632149791f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    550\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 850\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cate = [\"정치\",\"경제\",\"사회\", \"생활/문화\",\"세계\",\"기술/IT\", \"연예\", \"스포츠\"]\r\n",
    "def softmax(vals, idx):\r\n",
    "    valscpu = vals.cpu().detach().squeeze(0)\r\n",
    "    a = 0\r\n",
    "    for i in valscpu:\r\n",
    "        a += np.exp(i)\r\n",
    "    \r\n",
    "    tmp = []\r\n",
    "    for i in valscpu:\r\n",
    "        tmp.append(((np.exp(i))/a).item() * 100)\r\n",
    "    print([\"{}:{:.2f}%\".format(cate[i],v) for i,v in enumerate(tmp)])\r\n",
    "    return ((np.exp(valscpu[idx]))/a).item() * 100\r\n",
    "\r\n",
    "def test_model(seq, model):\r\n",
    "    model.eval()\r\n",
    "    sen = vocab.encode_as_pieces(seq)\r\n",
    "    l = min(max_len, len(sen))\r\n",
    "    sen = sen[:l]\r\n",
    "    sen = doc2vec_model.infer_vector(sen)\r\n",
    "    sen = torch.tensor(sen).unsqueeze(0).to(device)\r\n",
    "    result = model(sen)\r\n",
    "    idx = result.argmax().cpu().item()\r\n",
    "    print(\"뉴스의 카테고리는:\", cate[idx])\r\n",
    "    print(\"신뢰도는:\", \"{:.2f}%\".format(softmax(result,idx)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "test_model(\"신형 아이패드 프로에 m1칩 탑재 예정\", model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴스의 카테고리는: 기술/IT\n",
      "['정치:1.18%', '경제:10.40%', '사회:14.44%', '생활/문화:16.44%', '세계:5.13%', '기술/IT:30.20%', '연예:6.33%', '스포츠:15.89%']\n",
      "신뢰도는: 30.20%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "source": [
    "#대통령, 국회의원 지지율 감소\r\n",
    "#신형 아이패드 m1칩 탑재 예정\r\n",
    "#차명종 서대현 김라희 등 韓7명 호치민3쿠션월드컵 PPPQ통과"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "torch.save(model.state_dict(), \"news_doc2vec.pt\")\r\n",
    "modelload = Classifier(embed_num, 8).to(device)\r\n",
    "modelload.load_state_dict(torch.load(\"news_doc2vec.pt\", device))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "test_model(\"신형 아이패드 프로에 m1칩 탑재 예정\", model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "뉴스의 카테고리는: 기술/IT\n",
      "['정치:1.16%', '경제:10.74%', '사회:14.78%', '생활/문화:17.69%', '세계:6.43%', '기술/IT:28.67%', '연예:4.87%', '스포츠:15.66%']\n",
      "신뢰도는: 28.67%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}